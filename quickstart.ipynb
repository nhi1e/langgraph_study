{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab9b7800",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "\n",
    "load_dotenv()\n",
    "if \"OPENAI_API_KEY\" not in os.environ:\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API key: \")\n",
    "if \"LANGCHAIN_API_KEY\" not in os.environ:\n",
    "    os.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass(\"Enter your LangChain API key: \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "463c0a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import AnyMessage\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langgraph.prebuilt.chat_agent_executor import AgentState\n",
    "\n",
    "def prompt(state: AgentState, config: RunnableConfig) -> list[AnyMessage]:\n",
    "    user_name = config[\"configurable\"].get[\"user_name\"]\n",
    "    system_msg = f\"You are a helpful assistant for {user_name}. Address them by their name, as {user_name}.\"\n",
    "    return [{\"role\": \"system\", \"content\": system_msg}] + state[\"messages\"] \n",
    "\n",
    "# AnyMessage is any message in the chat, whether user or system\n",
    "# AgentState is a dictionary that keeps track of the current state of the\n",
    "# its \"messages\" key contains a list of messages so far\n",
    "# why is the return constructed this way?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "84b52949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response for SF: {'messages': [HumanMessage(content='what is the weather in sf', additional_kwargs={}, response_metadata={}, id='3560eeb0-f16c-4b73-9e7c-b2b9aadf8ba1'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_SpRRXzPSJ8OskyWYo8v4nt0b', 'function': {'arguments': '{\"city\":\"San Francisco\"}', 'name': 'get_weather_tool'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 54, 'total_tokens': 70, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_07871e2ad8', 'id': 'chatcmpl-Bmc7yYHLcPHYlVtYK4BGkOeLjEezr', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--3f39636f-99e1-49ff-be78-41496f37299e-0', tool_calls=[{'name': 'get_weather_tool', 'args': {'city': 'San Francisco'}, 'id': 'call_SpRRXzPSJ8OskyWYo8v4nt0b', 'type': 'tool_call'}], usage_metadata={'input_tokens': 54, 'output_tokens': 16, 'total_tokens': 70, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content=\"It's always sunny in San Francisco!\", name='get_weather_tool', id='dbb829f7-c27d-4edf-8193-7806c41915c9', tool_call_id='call_SpRRXzPSJ8OskyWYo8v4nt0b'), AIMessage(content='The weather in San Francisco is sunny! ☀️', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 12, 'prompt_tokens': 86, 'total_tokens': 98, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_07871e2ad8', 'id': 'chatcmpl-Bmc7zv9Svm2LZL4fwIHszxcToQhFa', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--a72efadc-a5ab-49c2-bf43-b366d727c24d-0', usage_metadata={'input_tokens': 86, 'output_tokens': 12, 'total_tokens': 98, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})], 'structured_response': WeatherResponse(city='San Francisco', condition='sunny')}\n",
      "Structured response for SF: {'city': 'San Francisco', 'condition': 'sunny'}\n"
     ]
    }
   ],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langchain.tools import tool\n",
    "from pydantic import BaseModel\n",
    "\n",
    "model = init_chat_model(\n",
    "    \"openai:gpt-4o\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "class WeatherResponse(BaseModel):\n",
    "    city: str \n",
    "    condition: str \n",
    "\n",
    "\n",
    "@tool\n",
    "def get_weather_tool(city: str) -> str:\n",
    "    \"\"\"Returns a fake weather report for the given city.\"\"\"\n",
    "    return f\"It's always sunny in {city}!\"\n",
    "\n",
    "checkpointer = InMemorySaver()\n",
    "\n",
    "agent = create_react_agent(\n",
    "    model = \"openai:gpt-4o\",\n",
    "    tools = [get_weather_tool],\n",
    "    # checkpointer = checkpointer,\n",
    "    response_format= WeatherResponse,\n",
    ")\n",
    "\n",
    "# Run the agent\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "sf_response = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"what is the weather in sf\"}]},\n",
    "    config  \n",
    ")\n",
    "# ny_response = agent.invoke(\n",
    "#     {\"messages\": [{\"role\": \"user\", \"content\": \"what about new york?\"}]},\n",
    "#     config\n",
    "# )\n",
    "print(\"Response for SF:\", sf_response)\n",
    "print(\"Structured response for SF:\", sf_response[\"structured_response\"].model_dump())\n",
    "\n",
    "# print(\"Response for NY:\", ny_response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
